{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German_Traffic_Sign_Recognition\n",
    "## About Dataset\n",
    "### Context\n",
    "The [German Traffic Sign Benchmark](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign?datasetId=82373)\n",
    " is a multi-class, single-image classification challenge held at the International Joint Conference on Neural Networks (IJCNN) 2011. We cordially invite researchers from relevant fields to participate: The competition is designed to allow for participation without special domain knowledge. Our benchmark has the following properties:\n",
    "\n",
    "* Single-image, multi-class classification problem\n",
    "* More than 40 classes\n",
    "* More than 50,000 images in total\n",
    "* Large, lifelike database\n",
    "\n",
    "**Acknowledgements** \\\n",
    "INI Benchmark Website\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# ignore all the warning and debug information from tensorflow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from libs.nn.conv.cnn import CNN\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from libs.utils.myplot import plot_confusion_matrix\n",
    "import matplotlib.image as img\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 13:24:00.801543: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look into the data directory\n",
    "images_dir = './gtsrb-german-traffic-sign'\n",
    "\n",
    "dataset_dir = f'{images_dir}/Train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_WIDTH = IMG_HEIGHT = 32\n",
    "RANDOM_STATE=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0: 'Speed limit (20km/h)',\n",
    "           1: 'Speed limit (30km/h)',\n",
    "           2: 'Speed limit (50km/h)',\n",
    "           3: 'Speed limit (60km/h)',\n",
    "           4: 'Speed limit (70km/h)',\n",
    "           5: 'Speed limit (80km/h)',\n",
    "           6: 'End of speed limit (80km/h)',\n",
    "           7: 'Speed limit (100km/h)',\n",
    "           8: 'Speed limit (120km/h)',\n",
    "           9: 'No passing',\n",
    "           10: 'No passing veh over 3.5 tons',\n",
    "           11: 'Right-of-way at intersection',\n",
    "           12: 'Priority road',\n",
    "           13: 'Yield',\n",
    "           14: 'Stop',\n",
    "           15: 'No vehicles',\n",
    "           16: 'Veh > 3.5 tons prohibited',\n",
    "           17: 'No entry',\n",
    "           18: 'General caution',\n",
    "           19: 'Dangerous curve left',\n",
    "           20: 'Dangerous curve right',\n",
    "           21: 'Double curve',\n",
    "           22: 'Bumpy road',\n",
    "           23: 'Slippery road',\n",
    "           24: 'Road narrows on the right',\n",
    "           25: 'Road work',\n",
    "           26: 'Traffic signals',\n",
    "           27: 'Pedestrians',\n",
    "           28: 'Children crossing',\n",
    "           29: 'Bicycles crossing',\n",
    "           30: 'Beware of ice/snow',\n",
    "           31: 'Wild animals crossing',\n",
    "           32: 'End speed + passing limits',\n",
    "           33: 'Turn right ahead',\n",
    "           34: 'Turn left ahead',\n",
    "           35: 'Ahead only',\n",
    "           36: 'Go straight or right',\n",
    "           37: 'Go straight or left',\n",
    "           38: 'Keep right',\n",
    "           39: 'Keep left',\n",
    "           40: 'Roundabout mandatory',\n",
    "           41: 'End of no passing',\n",
    "           42: 'End no passing veh > 3.5 tons'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39209 files belonging to 43 classes.\n",
      "Using 31368 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "  dataset_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=42,\n",
    "  shuffle=True,\n",
    "  label_mode='categorical' ,\n",
    "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39209 files belonging to 43 classes.\n",
      "Using 7841 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "  dataset_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  label_mode='categorical' ,\n",
    "  shuffle=True,\n",
    "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  seed=42,\n",
    "  batch_size=BATCH_SIZE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 12.        11.        13.      ]\n",
      "   [ 12.        11.        14.      ]\n",
      "   [ 12.        10.        13.      ]\n",
      "   ...\n",
      "   [ 12.        11.        14.      ]\n",
      "   [ 12.        10.        13.      ]\n",
      "   [ 11.        10.        13.      ]]\n",
      "\n",
      "  [[ 12.        11.        13.      ]\n",
      "   [ 11.        10.        13.      ]\n",
      "   [ 12.        10.        12.      ]\n",
      "   ...\n",
      "   [ 11.        10.        13.      ]\n",
      "   [ 13.        11.        13.      ]\n",
      "   [ 11.        10.        12.      ]]\n",
      "\n",
      "  [[ 13.        11.        13.      ]\n",
      "   [ 13.        11.        13.      ]\n",
      "   [ 12.        10.        12.      ]\n",
      "   ...\n",
      "   [ 10.         9.        11.      ]\n",
      "   [ 12.        10.        12.      ]\n",
      "   [ 12.        10.        12.      ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 13.        11.        13.      ]\n",
      "   [ 12.        10.        13.      ]\n",
      "   [ 13.        11.        14.      ]\n",
      "   ...\n",
      "   [ 14.        12.        14.      ]\n",
      "   [ 13.        12.        15.      ]\n",
      "   [ 13.        11.        15.      ]]\n",
      "\n",
      "  [[ 12.        10.        12.      ]\n",
      "   [ 12.        10.        13.      ]\n",
      "   [ 13.        10.        13.      ]\n",
      "   ...\n",
      "   [ 15.        13.        15.      ]\n",
      "   [ 14.        12.        15.      ]\n",
      "   [ 14.        12.        15.      ]]\n",
      "\n",
      "  [[ 12.        11.        14.      ]\n",
      "   [ 12.        10.        14.      ]\n",
      "   [ 13.        10.        13.      ]\n",
      "   ...\n",
      "   [ 16.        13.        16.      ]\n",
      "   [ 16.        14.        17.      ]\n",
      "   [ 13.        11.        14.      ]]]\n",
      "\n",
      "\n",
      " [[[233.6836   237.85742  254.08691 ]\n",
      "   [249.22559  245.50781  234.19531 ]\n",
      "   [244.4541   242.1377   250.11816 ]\n",
      "   ...\n",
      "   [145.87207  137.60645  143.75977 ]\n",
      "   [176.85449  185.32715  194.87207 ]\n",
      "   [190.35156  182.44238  181.69922 ]]\n",
      "\n",
      "  [[250.11035  246.2959   239.76562 ]\n",
      "   [238.2832   226.46582  230.86816 ]\n",
      "   [231.75586  219.53906  232.21875 ]\n",
      "   ...\n",
      "   [144.19238  132.04102  142.51172 ]\n",
      "   [146.79395  147.7334   155.58008 ]\n",
      "   [162.13281  152.89453  153.64941 ]]\n",
      "\n",
      "  [[208.8916   195.83301  213.2168  ]\n",
      "   [173.84961  179.66992  191.15918 ]\n",
      "   [228.69629  210.91797  222.71582 ]\n",
      "   ...\n",
      "   [116.17578  110.549805 112.65918 ]\n",
      "   [138.29199  133.14941  136.83691 ]\n",
      "   [138.23242  135.75684  140.19434 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 85.71582   78.762695  71.043945]\n",
      "   [ 75.578125  75.265625  71.11133 ]\n",
      "   [ 80.5625    82.65625   75.299805]\n",
      "   ...\n",
      "   [ 77.63867   72.91992   72.80859 ]\n",
      "   [ 90.180664  85.49512   81.83594 ]\n",
      "   [ 86.399414  82.82031   82.46777 ]]\n",
      "\n",
      "  [[ 94.078125  83.43848   74.97461 ]\n",
      "   [ 88.20117   85.18555   76.3457  ]\n",
      "   [ 84.68262   83.43945   73.418945]\n",
      "   ...\n",
      "   [ 83.51465   76.25098   74.7334  ]\n",
      "   [101.26172   95.853516  92.2959  ]\n",
      "   [ 92.47754   86.56543   85.39746 ]]\n",
      "\n",
      "  [[ 92.75879   85.71387   84.49512 ]\n",
      "   [ 83.42969   82.887695  78.12793 ]\n",
      "   [ 85.112305  89.331055  76.44043 ]\n",
      "   ...\n",
      "   [ 98.493164  89.59961   89.174805]\n",
      "   [ 90.89746   83.43945   79.69531 ]\n",
      "   [ 98.94629   96.16504   94.59375 ]]]\n",
      "\n",
      "\n",
      " [[[ 80.987305  94.61914  120.25488 ]\n",
      "   [ 69.14453   83.60254  106.19531 ]\n",
      "   [ 68.25781   78.80664  101.12402 ]\n",
      "   ...\n",
      "   [ 84.80664  103.2041   135.09473 ]\n",
      "   [ 86.69141  106.1416   143.31055 ]\n",
      "   [ 93.20801  109.38965  144.54199 ]]\n",
      "\n",
      "  [[ 79.27539   81.81152  101.72754 ]\n",
      "   [ 51.384766  66.680664  81.26758 ]\n",
      "   [ 55.801758  65.79199   83.697266]\n",
      "   ...\n",
      "   [ 87.79883  105.01172  131.93848 ]\n",
      "   [ 84.07422  100.75586  137.49707 ]\n",
      "   [ 87.98242  107.37012  144.85254 ]]\n",
      "\n",
      "  [[ 71.299805  79.586914  99.70117 ]\n",
      "   [ 62.884766  71.32422   85.131836]\n",
      "   [ 59.862305  68.34277   88.5     ]\n",
      "   ...\n",
      "   [ 76.444336  92.0791   114.25781 ]\n",
      "   [ 74.61426   93.572266 125.79492 ]\n",
      "   [ 81.36719  100.26465  137.73047 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 59.69922   62.69922   70.05664 ]\n",
      "   [ 58.905273  62.21289   68.197266]\n",
      "   [ 59.174805  62.174805  68.03418 ]\n",
      "   ...\n",
      "   [ 11.53418   11.        15.362305]\n",
      "   [ 11.270508  11.129883  15.734375]\n",
      "   [ 11.209961  12.538086  18.30371 ]]\n",
      "\n",
      "  [[ 42.479492  43.354492  48.600586]\n",
      "   [ 34.873047  35.748047  37.947266]\n",
      "   [ 30.094727  31.204102  33.1416  ]\n",
      "   ...\n",
      "   [ 14.078125  15.03125   21.567383]\n",
      "   [ 16.60254   17.771484  23.618164]\n",
      "   [ 17.389648  19.232422  25.041992]]\n",
      "\n",
      "  [[ 31.14746   30.308594  40.854492]\n",
      "   [ 31.836914  32.49121   40.353516]\n",
      "   [ 32.20996   32.027344  33.027344]\n",
      "   ...\n",
      "   [ 20.911133  24.426758  32.308594]\n",
      "   [ 24.904297  29.09082   38.66992 ]\n",
      "   [ 27.563477  30.03711   37.515625]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[255.       255.       255.      ]\n",
      "   [255.       255.       255.      ]\n",
      "   [255.       255.       255.      ]\n",
      "   ...\n",
      "   [255.       255.       255.      ]\n",
      "   [255.       255.       255.      ]\n",
      "   [255.       255.       255.      ]]\n",
      "\n",
      "  [[255.       255.       255.      ]\n",
      "   [255.       255.       255.      ]\n",
      "   [255.       255.       255.      ]\n",
      "   ...\n",
      "   [255.       255.       255.      ]\n",
      "   [255.       255.       255.      ]\n",
      "   [255.       255.       255.      ]]\n",
      "\n",
      "  [[255.       255.       255.      ]\n",
      "   [255.       255.       255.      ]\n",
      "   [255.       255.       255.      ]\n",
      "   ...\n",
      "   [255.       255.       255.      ]\n",
      "   [255.       255.       255.      ]\n",
      "   [255.       255.       255.      ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 53.        40.        29.      ]\n",
      "   [ 76.        97.        73.      ]\n",
      "   [123.       117.       107.      ]\n",
      "   ...\n",
      "   [255.       255.       255.      ]\n",
      "   [244.       255.       255.      ]\n",
      "   [208.       229.       238.      ]]\n",
      "\n",
      "  [[ 62.        72.        45.      ]\n",
      "   [ 46.        46.        51.      ]\n",
      "   [ 40.        52.        51.      ]\n",
      "   ...\n",
      "   [255.       255.       255.      ]\n",
      "   [228.       250.       255.      ]\n",
      "   [ 75.        76.        72.      ]]\n",
      "\n",
      "  [[144.       162.       162.      ]\n",
      "   [188.       123.       120.      ]\n",
      "   [117.        93.       110.      ]\n",
      "   ...\n",
      "   [255.       255.       255.      ]\n",
      "   [255.       255.       255.      ]\n",
      "   [255.       240.       238.      ]]]\n",
      "\n",
      "\n",
      " [[[ 46.484375  47.828125  53.125   ]\n",
      "   [ 55.320312  52.601562  57.726562]\n",
      "   [ 67.328125  71.44531   81.92969 ]\n",
      "   ...\n",
      "   [ 38.570312  37.46875   39.734375]\n",
      "   [ 40.859375  39.40625   41.351562]\n",
      "   [ 51.03125   50.898438  54.671875]]\n",
      "\n",
      "  [[ 55.679688  51.546875  56.804688]\n",
      "   [ 59.375     62.46875   67.14844 ]\n",
      "   [ 67.88281   71.03906   80.71094 ]\n",
      "   ...\n",
      "   [ 41.765625  37.453125  40.46875 ]\n",
      "   [ 52.132812  49.0625    52.078125]\n",
      "   [ 65.71875   66.47656   77.      ]]\n",
      "\n",
      "  [[ 68.75      73.53125   86.609375]\n",
      "   [ 53.140625  75.10156   91.046875]\n",
      "   [ 45.734375  58.078125  76.9375  ]\n",
      "   ...\n",
      "   [ 56.640625  53.585938  61.960938]\n",
      "   [ 70.72656   65.74219   70.61719 ]\n",
      "   [ 90.        91.19531  105.21875 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 20.710938  20.796875  24.710938]\n",
      "   [ 21.796875  20.976562  24.039062]\n",
      "   [ 22.171875  22.242188  24.75    ]\n",
      "   ...\n",
      "   [ 22.15625   22.210938  26.523438]\n",
      "   [ 19.671875  19.984375  26.679688]\n",
      "   [ 17.898438  18.375     23.734375]]\n",
      "\n",
      "  [[ 19.835938  19.921875  23.234375]\n",
      "   [ 20.921875  20.921875  24.804688]\n",
      "   [ 21.296875  21.859375  25.734375]\n",
      "   ...\n",
      "   [ 23.523438  23.960938  26.140625]\n",
      "   [ 19.617188  21.679688  25.039062]\n",
      "   [ 17.023438  18.648438  24.9375  ]]\n",
      "\n",
      "  [[ 21.492188  20.546875  24.289062]\n",
      "   [ 20.023438  20.375     24.960938]\n",
      "   [ 20.726562  21.101562  26.726562]\n",
      "   ...\n",
      "   [ 22.234375  22.398438  25.023438]\n",
      "   [ 20.523438  21.335938  24.359375]\n",
      "   [ 20.789062  21.59375   25.226562]]]\n",
      "\n",
      "\n",
      " [[[ 11.772949   9.022949  11.101074]\n",
      "   [  9.328125   8.868652  11.890625]\n",
      "   [ 11.155762  11.765137  15.249512]\n",
      "   ...\n",
      "   [ 10.495117   9.552246  12.458496]\n",
      "   [ 11.578125  11.365723  14.34375 ]\n",
      "   [ 13.569824  13.569824  16.569824]]\n",
      "\n",
      "  [[ 11.865723  10.021973  12.100098]\n",
      "   [ 10.383789  10.618164  13.786621]\n",
      "   [ 10.71875   11.328125  15.4375  ]\n",
      "   ...\n",
      "   [  9.390625   9.28125   11.28125 ]\n",
      "   [  9.980957  10.046875  12.8125  ]\n",
      "   [ 11.203125  10.943848  13.943848]]\n",
      "\n",
      "  [[ 11.057617   9.645996  12.192871]\n",
      "   [ 10.875488  11.        14.358887]\n",
      "   [ 10.46875   10.79248   14.      ]\n",
      "   ...\n",
      "   [ 10.14502   10.285645  12.754395]\n",
      "   [ 10.750977  10.875488  13.750977]\n",
      "   [ 11.921875  11.432129  14.432129]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 20.49414   16.671387  18.223145]\n",
      "   [ 15.53125   13.296875  15.828125]\n",
      "   [ 13.609375  12.53125   15.27002 ]\n",
      "   ...\n",
      "   [ 14.421387  16.108887  16.492676]\n",
      "   [ 15.751465  19.344727  20.405762]\n",
      "   [ 21.483398  26.774902  28.536133]]\n",
      "\n",
      "  [[ 20.203125  18.        19.818848]\n",
      "   [ 16.800293  15.584961  18.58496 ]\n",
      "   [ 14.608887  13.999512  17.109375]\n",
      "   ...\n",
      "   [ 13.89209   14.672852  13.829102]\n",
      "   [ 13.658203  15.154785  14.095703]\n",
      "   [ 15.790527  17.612305  17.265137]]\n",
      "\n",
      "  [[ 21.671875  21.4917    24.476074]\n",
      "   [ 18.415527  18.109375  21.803223]\n",
      "   [ 16.458496  15.849121  18.849121]\n",
      "   ...\n",
      "   [ 11.541504  11.598633  14.317383]\n",
      "   [ 11.80957   11.90332   14.62207 ]\n",
      "   [ 12.172852  12.266602  14.985352]]]], shape=(32, 32, 32, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(32, 43), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels are already one-hot encoded, now we have to normalize the images, that will be done in side the model (1st Sequential layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare CNN Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20,\n",
    "                                                     restore_best_weights=True)\n",
    "\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model/ge_traffic_sign\",\n",
    "                                                         save_best_only=True)\n",
    "\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = Path() / \"ge_traffic_sign_recog\" / f\"run_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 20)        1520      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 20)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 50)        25050     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 50)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3200)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               1600500   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 43)                21543     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,648,613\n",
      "Trainable params: 1,648,613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model = CNN.build(width=IMG_WIDTH, height=IMG_HEIGHT, depth= 3, classes=len(classes.keys()))\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, weight_decay=0.01/EPOCHS, momentum=0.9, nesterov=True)\n",
    "cnn_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "979/981 [============================>.] - ETA: 0s - loss: 0.9591 - accuracy: 0.7360"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981/981 [==============================] - 14s 13ms/step - loss: 0.9573 - accuracy: 0.7364 - val_loss: 0.2101 - val_accuracy: 0.9453\n",
      "Epoch 2/100\n",
      "978/981 [============================>.] - ETA: 0s - loss: 0.1045 - accuracy: 0.9706"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981/981 [==============================] - 13s 13ms/step - loss: 0.1043 - accuracy: 0.9707 - val_loss: 0.0874 - val_accuracy: 0.9767\n",
      "Epoch 3/100\n",
      "979/981 [============================>.] - ETA: 0s - loss: 0.0432 - accuracy: 0.9887"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981/981 [==============================] - 13s 13ms/step - loss: 0.0431 - accuracy: 0.9887 - val_loss: 0.0565 - val_accuracy: 0.9862\n",
      "Epoch 4/100\n",
      "978/981 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981/981 [==============================] - 13s 13ms/step - loss: 0.0237 - accuracy: 0.9941 - val_loss: 0.0508 - val_accuracy: 0.9862\n",
      "Epoch 5/100\n",
      "979/981 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981/981 [==============================] - 13s 13ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.0448 - val_accuracy: 0.9893\n",
      "Epoch 6/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.0466 - val_accuracy: 0.9897\n",
      "Epoch 7/100\n",
      "978/981 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9988"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981/981 [==============================] - 13s 13ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.0340 - val_accuracy: 0.9918\n",
      "Epoch 8/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0381 - val_accuracy: 0.9915\n",
      "Epoch 9/100\n",
      "981/981 [==============================] - 12s 12ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0486 - val_accuracy: 0.9879\n",
      "Epoch 10/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0406 - val_accuracy: 0.9913\n",
      "Epoch 11/100\n",
      "981/981 [==============================] - 12s 12ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0349 - val_accuracy: 0.9912\n",
      "Epoch 12/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0357 - val_accuracy: 0.9931\n",
      "Epoch 13/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 5.8568e-04 - accuracy: 0.9999 - val_loss: 0.0371 - val_accuracy: 0.9930\n",
      "Epoch 14/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 2.9883e-04 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9927\n",
      "Epoch 15/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 2.2560e-04 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9927\n",
      "Epoch 16/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 1.9253e-04 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9927\n",
      "Epoch 17/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 1.8072e-04 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9930\n",
      "Epoch 18/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 1.6022e-04 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9927\n",
      "Epoch 19/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 1.5781e-04 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9927\n",
      "Epoch 20/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 1.4020e-04 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9929\n",
      "Epoch 21/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 1.3241e-04 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9929\n",
      "Epoch 22/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 1.2957e-04 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9927\n",
      "Epoch 23/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 1.2079e-04 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9930\n",
      "Epoch 24/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 1.1666e-04 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9926\n",
      "Epoch 25/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 1.1351e-04 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9930\n",
      "Epoch 26/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 1.1090e-04 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9929\n",
      "Epoch 27/100\n",
      "981/981 [==============================] - 12s 13ms/step - loss: 1.0606e-04 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9929\n"
     ]
    }
   ],
   "source": [
    "history = cnn_model.fit(train_ds,\n",
    "                        validation_data=val_ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.03404991701245308, 0.9918377995491028)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = cnn_model.evaluate(val_ds)\n",
    "loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 1s 2ms/step\n",
      "[1.4489695e-12 3.7667612e-11 7.5941632e-18 4.5475181e-18 1.6238004e-19\n",
      " 1.4816438e-18 5.3142207e-16 2.3486223e-13 1.1677040e-13 3.2339172e-15\n",
      " 4.4700914e-16 1.8809415e-19 4.2194807e-15 3.9425572e-15 2.3595455e-18\n",
      " 3.6156654e-19 5.4207656e-18 5.1357079e-13 1.8430396e-21 2.2535534e-13\n",
      " 4.2865307e-16 1.4457133e-14 3.6987057e-15 1.9481087e-21 1.8919185e-16\n",
      " 2.4108277e-15 1.1105352e-16 2.0704048e-16 3.7527067e-18 1.2238691e-17\n",
      " 1.5810380e-19 6.7383656e-15 5.0092181e-19 7.4163809e-17 4.6142608e-07\n",
      " 9.9391610e-13 1.3251411e-18 8.3127674e-17 3.0955700e-11 6.0845180e-15\n",
      " 3.6577655e-06 9.9999577e-01 1.6460426e-16]\n",
      "[3.54908707e-11 7.54922596e-08 2.92518118e-04 1.42217411e-08\n",
      " 1.05540614e-07 3.57835916e-09 4.74440498e-07 5.89139537e-09\n",
      " 2.18542959e-06 1.28778987e-10 4.45993003e-08 7.22740534e-10\n",
      " 2.27852997e-05 3.12217807e-09 2.95810987e-10 3.30160378e-13\n",
      " 1.65348935e-09 2.55305537e-08 6.64671829e-09 3.55144856e-08\n",
      " 3.38615891e-09 4.94482955e-10 1.88038224e-10 5.29817719e-08\n",
      " 3.54788767e-08 3.53163649e-08 9.25639565e-10 3.49432809e-12\n",
      " 1.79847890e-12 1.27030317e-10 1.98341725e-11 1.07655014e-08\n",
      " 1.32133970e-10 1.08521759e-11 1.53121107e-07 1.25269617e-09\n",
      " 2.36158398e-10 1.11853396e-05 2.78350781e-04 1.01011707e-07\n",
      " 9.99384999e-01 4.46649801e-06 2.36750611e-06]\n",
      "[2.9886949e-13 2.1007793e-11 2.6664743e-06 2.1479366e-06 9.9999100e-01\n",
      " 1.4424854e-08 1.7909561e-10 1.1630085e-13 2.6114595e-09 4.4096149e-09\n",
      " 8.4694630e-12 1.2051331e-09 7.3014365e-13 6.0761414e-07 1.7000296e-08\n",
      " 9.9737479e-14 1.6891106e-09 1.7820479e-11 1.5923808e-10 3.8059927e-08\n",
      " 2.2871902e-12 1.2146788e-11 1.0483990e-12 1.3225102e-12 8.8992103e-09\n",
      " 4.2960899e-11 1.0539835e-07 1.1052205e-11 9.1591977e-11 3.6265064e-11\n",
      " 4.7828930e-10 2.4069033e-10 9.4401778e-11 3.9430555e-12 7.7684732e-16\n",
      " 7.3704887e-09 1.3588887e-07 2.3698296e-06 1.0502328e-11 9.0047376e-07\n",
      " 1.6966686e-10 8.9575420e-15 8.1357783e-09]\n"
     ]
    }
   ],
   "source": [
    "predicted = cnn_model.predict(val_ds)\n",
    "for pred in predicted[:3]:\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual_predicted_labels(dataset): \n",
    "  \"\"\"\n",
    "    Create a list of actual ground truth values and the predictions from the model.\n",
    "\n",
    "    Args:\n",
    "      dataset: An iterable data structure, such as a TensorFlow Dataset, with features and labels.\n",
    "\n",
    "    Return:\n",
    "      Ground truth and predicted values for a particular dataset.\n",
    "  \"\"\"\n",
    "  actual = [labels for _, labels in dataset.unbatch()]\n",
    "  predicted = cnn_model.predict(dataset)\n",
    "\n",
    "  actual = tf.stack(actual, axis=0)\n",
    "  actual =np.argmax(actual, axis=1) # because one hot encoded \n",
    "  predicted = tf.concat(predicted, axis=0)\n",
    "  predicted = tf.argmax(predicted, axis=1)\n",
    "\n",
    "  return actual, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([41, 40,  4,  3,  3, 24, 41,  5,  1, 18]),\n",
       " array([41, 40,  4,  3,  3, 24, 41,  5,  1, 18]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual, predicted = get_actual_predicted_labels(val_ds)\n",
    "actual[:10], predicted[:10].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        44\n",
      "           1       0.99      0.99      0.99       448\n",
      "           2       0.99      1.00      1.00       390\n",
      "           3       0.99      0.99      0.99       297\n",
      "           4       0.99      1.00      0.99       396\n",
      "           5       1.00      0.99      0.99       441\n",
      "           6       1.00      0.99      1.00       173\n",
      "           7       0.99      0.99      0.99       146\n",
      "           8       1.00      1.00      1.00        82\n",
      "           9       1.00      1.00      1.00       206\n",
      "          10       1.00      1.00      1.00       248\n",
      "          11       1.00      0.98      0.99        46\n",
      "          12       1.00      0.99      1.00       429\n",
      "          13       0.93      1.00      0.96        67\n",
      "          14       0.95      0.99      0.97        75\n",
      "          15       0.99      1.00      0.99        89\n",
      "          16       1.00      0.97      0.98        98\n",
      "          17       1.00      1.00      1.00        52\n",
      "          18       0.99      0.99      0.99       298\n",
      "          19       0.98      0.99      0.98       123\n",
      "          20       1.00      0.98      0.99        62\n",
      "          21       0.98      0.98      0.98       115\n",
      "          22       0.98      0.94      0.96        49\n",
      "          23       0.99      1.00      0.99       261\n",
      "          24       0.98      0.98      0.98       109\n",
      "          25       0.99      1.00      1.00       171\n",
      "          26       1.00      1.00      1.00        58\n",
      "          27       1.00      0.98      0.99       128\n",
      "          28       0.98      1.00      0.99        88\n",
      "          29       1.00      1.00      1.00       248\n",
      "          30       0.96      0.99      0.97        74\n",
      "          31       1.00      0.98      0.99        47\n",
      "          32       1.00      1.00      1.00       439\n",
      "          33       1.00      1.00      1.00        56\n",
      "          34       1.00      0.99      1.00       350\n",
      "          35       0.99      1.00      0.99        77\n",
      "          36       1.00      1.00      1.00        49\n",
      "          37       1.00      1.00      1.00        43\n",
      "          38       0.98      0.98      0.98       327\n",
      "          39       0.99      1.00      0.99        87\n",
      "          40       1.00      0.98      0.99       275\n",
      "          41       0.99      1.00      0.99       275\n",
      "          42       0.99      0.99      0.99       305\n",
      "\n",
      "    accuracy                           0.99      7841\n",
      "   macro avg       0.99      0.99      0.99      7841\n",
      "weighted avg       0.99      0.99      0.99      7841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual, predicted))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = 'model/ge_traffic_sign_recognition.h5'\n",
    "cnn_model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "German_Traffic_Sign_Recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d537c92fe30561e09db272b7a25ae30e6e2bc97a97b3734491f304a50020ffea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
