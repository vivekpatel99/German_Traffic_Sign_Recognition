{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German_Traffic_Sign_Recognition\n",
    "## About Dataset\n",
    "### Context\n",
    "The [German Traffic Sign Benchmark](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign?datasetId=82373)\n",
    " is a multi-class, single-image classification challenge held at the International Joint Conference on Neural Networks (IJCNN) 2011. We cordially invite researchers from relevant fields to participate: The competition is designed to allow for participation without special domain knowledge. Our benchmark has the following properties:\n",
    "\n",
    "* Single-image, multi-class classification problem\n",
    "* More than 40 classes\n",
    "* More than 50,000 images in total\n",
    "* Large, lifelike database\n",
    "\n",
    "**Acknowledgements** \\\n",
    "INI Benchmark Website\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# ignore all the warning and debug information from tensorflow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from libs.nn.conv.lenet import LeNet\n",
    "from libs.nn.conv.minivggnet import MiniVGGNet\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus: \n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look into the data directory\n",
    "images_dir = './gtsrb-german-traffic-sign'\n",
    "\n",
    "dataset_dir = f'{images_dir}/Train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_WIDTH = IMG_HEIGHT = 32\n",
    "RANDOM_STATE=123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0: 'Speed limit (20km/h)',\n",
    "           1: 'Speed limit (30km/h)',\n",
    "           2: 'Speed limit (50km/h)',\n",
    "           3: 'Speed limit (60km/h)',\n",
    "           4: 'Speed limit (70km/h)',\n",
    "           5: 'Speed limit (80km/h)',\n",
    "           6: 'End of speed limit (80km/h)',\n",
    "           7: 'Speed limit (100km/h)',\n",
    "           8: 'Speed limit (120km/h)',\n",
    "           9: 'No passing',\n",
    "           10: 'No passing veh over 3.5 tons',\n",
    "           11: 'Right-of-way at intersection',\n",
    "           12: 'Priority road',\n",
    "           13: 'Yield',\n",
    "           14: 'Stop',\n",
    "           15: 'No vehicles',\n",
    "           16: 'Veh > 3.5 tons prohibited',\n",
    "           17: 'No entry',\n",
    "           18: 'General caution',\n",
    "           19: 'Dangerous curve left',\n",
    "           20: 'Dangerous curve right',\n",
    "           21: 'Double curve',\n",
    "           22: 'Bumpy road',\n",
    "           23: 'Slippery road',\n",
    "           24: 'Road narrows on the right',\n",
    "           25: 'Road work',\n",
    "           26: 'Traffic signals',\n",
    "           27: 'Pedestrians',\n",
    "           28: 'Children crossing',\n",
    "           29: 'Bicycles crossing',\n",
    "           30: 'Beware of ice/snow',\n",
    "           31: 'Wild animals crossing',\n",
    "           32: 'End speed + passing limits',\n",
    "           33: 'Turn right ahead',\n",
    "           34: 'Turn left ahead',\n",
    "           35: 'Ahead only',\n",
    "           36: 'Go straight or right',\n",
    "           37: 'Go straight or left',\n",
    "           38: 'Keep right',\n",
    "           39: 'Keep left',\n",
    "           40: 'Roundabout mandatory',\n",
    "           41: 'End of no passing',\n",
    "           42: 'End no passing veh > 3.5 tons'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39209 files belonging to 43 classes.\n",
      "Using 31368 files for training.\n",
      "Using 7841 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
    "  dataset_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"both\",\n",
    "  seed=RANDOM_STATE,\n",
    "  shuffle=True,\n",
    "  label_mode='categorical' ,\n",
    "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '2',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '3',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '4',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes  = train_ds.class_names\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 95.40918    96.18945    96.23633  ]\n",
      "   [ 96.25928    93.7876     90.0874   ]\n",
      "   [ 97.15723    93.31348    84.41748  ]\n",
      "   ...\n",
      "   [ 75.96875    79.30176    65.57764  ]\n",
      "   [ 72.30908    76.35303    64.97803  ]\n",
      "   [ 71.15723    75.0708     63.242676 ]]\n",
      "\n",
      "  [[ 98.328125   99.55322   102.05957  ]\n",
      "   [ 94.282715   94.67676    93.20459  ]\n",
      "   [ 97.46777    98.3125     89.6875   ]\n",
      "   ...\n",
      "   [ 71.21875    76.17041    63.38965  ]\n",
      "   [ 70.28662    75.16846    64.765625 ]\n",
      "   [ 71.640625   74.481445   63.55957  ]]\n",
      "\n",
      "  [[ 97.39697    99.86572   101.24072  ]\n",
      "   [ 96.88916    99.24805    97.13867  ]\n",
      "   [101.004395  104.38379    94.38818  ]\n",
      "   ...\n",
      "   [ 68.42432    74.975586   63.84619  ]\n",
      "   [ 67.87598    74.28223    64.157715 ]\n",
      "   [ 69.947754   72.65088    61.729004 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 99.115234  106.54736    86.07861  ]\n",
      "   [ 93.31494   100.32959    80.095215 ]\n",
      "   [ 92.995605  100.265625   81.370605 ]\n",
      "   ...\n",
      "   [ 66.31006    67.35254    58.04004  ]\n",
      "   [ 64.07617    64.186035   56.82715  ]\n",
      "   [ 60.952637   60.578125   55.91162  ]]\n",
      "\n",
      "  [[ 98.331055  104.72461    84.72461  ]\n",
      "   [ 91.072754   99.36279    79.42871  ]\n",
      "   [ 86.282715   96.82959    77.501465 ]\n",
      "   ...\n",
      "   [ 66.2334     65.467285   55.686035 ]\n",
      "   [ 59.251953   59.465332   51.996582 ]\n",
      "   [ 55.706543   58.672363   53.112793 ]]\n",
      "\n",
      "  [[ 92.37695    99.29785    78.3916   ]\n",
      "   [ 89.63086    97.00293    76.09668  ]\n",
      "   [ 89.11865    98.14453    77.2749   ]\n",
      "   ...\n",
      "   [ 62.90088    62.78662    53.00537  ]\n",
      "   [ 58.64746    59.36914    51.90039  ]\n",
      "   [ 56.890625   58.98535    50.40088  ]]]\n",
      "\n",
      "\n",
      " [[[ 50.6084     44.6084     40.20215  ]\n",
      "   [ 47.84961    42.41211    36.118164 ]\n",
      "   [ 47.844727   43.125977   36.125977 ]\n",
      "   ...\n",
      "   [ 92.4668     86.79004    74.7793   ]\n",
      "   [ 85.049805   75.91797    62.717773 ]\n",
      "   [ 94.288086   81.69238    68.896484 ]]\n",
      "\n",
      "  [[ 53.819336   47.24414    40.762695 ]\n",
      "   [ 49.01367    44.16992    36.13867  ]\n",
      "   [ 48.305664   45.15039    38.18164  ]\n",
      "   ...\n",
      "   [ 93.18457    84.30859    69.31152  ]\n",
      "   [ 89.73242    79.57617    64.54492  ]\n",
      "   [ 88.20117    78.70703    66.913086 ]]\n",
      "\n",
      "  [[ 55.333984   49.46875    40.65625  ]\n",
      "   [ 54.97168    46.75293    37.910156 ]\n",
      "   [ 54.61621    47.442383   41.192383 ]\n",
      "   ...\n",
      "   [101.0791     94.8291     82.18555  ]\n",
      "   [ 88.56738    81.06738    68.09961  ]\n",
      "   [ 77.71094    73.30371    62.242188 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 59.000977   58.16797    47.157227 ]\n",
      "   [ 71.81152    70.03027    55.936523 ]\n",
      "   [ 96.22168    92.70801    80.98535  ]\n",
      "   ...\n",
      "   [ 80.98047    66.44531    54.47168  ]\n",
      "   [ 49.964844   48.341797   41.185547 ]\n",
      "   [ 43.09375    44.21875    38.051758 ]]\n",
      "\n",
      "  [[ 58.375      57.96875    48.75586  ]\n",
      "   [ 72.01367    69.975586   58.288086 ]\n",
      "   [ 99.46484    97.4043     80.37793  ]\n",
      "   ...\n",
      "   [102.07422    76.643555   65.57715  ]\n",
      "   [ 53.930664   50.04883    44.368164 ]\n",
      "   [ 45.174805   45.1875     38.018555 ]]\n",
      "\n",
      "  [[ 54.31836    55.17871    43.27246  ]\n",
      "   [ 63.668945   63.64453    52.71289  ]\n",
      "   [ 96.791016   97.12402    80.58301  ]\n",
      "   ...\n",
      "   [114.97363    81.859375   62.19043  ]\n",
      "   [ 54.799805   50.512695   44.76953  ]\n",
      "   [ 45.910156   45.566406   39.768555 ]]]\n",
      "\n",
      "\n",
      " [[[ 36.0625     35.03125    37.03125  ]\n",
      "   [ 38.         35.90625    37.90625  ]\n",
      "   [ 37.53125    34.84375    36.84375  ]\n",
      "   ...\n",
      "   [ 45.84375    44.84375    49.       ]\n",
      "   [ 46.         44.09375    46.28125  ]\n",
      "   [ 48.90625    46.90625    47.9375   ]]\n",
      "\n",
      "  [[ 33.23291    32.231445   33.308105 ]\n",
      "   [ 36.004395   34.953125   37.04248  ]\n",
      "   [ 34.969727   34.03955    37.1416   ]\n",
      "   ...\n",
      "   [ 45.337402   43.384277   50.250977 ]\n",
      "   [ 44.183105   42.1875     45.506836 ]\n",
      "   [ 46.07666    44.07666    44.214355 ]]\n",
      "\n",
      "  [[ 34.822266   32.958008   34.911133 ]\n",
      "   [ 33.976074   33.984375   36.913574 ]\n",
      "   [ 31.934082   32.934082   35.94629  ]\n",
      "   ...\n",
      "   [ 47.934082   45.79004    50.024414 ]\n",
      "   [ 46.023926   44.023926   46.3042   ]\n",
      "   [ 44.208984   42.208984   43.166992 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 35.         32.075684   37.15625  ]\n",
      "   [ 35.09375    32.         37.148926 ]\n",
      "   [ 36.012207   32.15625    37.234375 ]\n",
      "   ...\n",
      "   [ 44.222168   42.15625    45.921875 ]\n",
      "   [ 43.313477   40.3291     43.344727 ]\n",
      "   [ 42.114258   39.111816   42.03369  ]]\n",
      "\n",
      "  [[ 35.095215   33.063965   39.04834  ]\n",
      "   [ 35.225586   32.131836   38.99121  ]\n",
      "   [ 36.21045    32.21045    38.163574 ]\n",
      "   ...\n",
      "   [ 45.09375    42.25       45.09375  ]\n",
      "   [ 45.95752    42.00879    44.10254  ]\n",
      "   [ 43.186035   40.10791    42.10791  ]]\n",
      "\n",
      "  [[ 37.03125    35.         40.03125  ]\n",
      "   [ 37.90625    34.8125     40.71875  ]\n",
      "   [ 37.3125     33.3125     38.3125   ]\n",
      "   ...\n",
      "   [ 47.         44.15625    47.       ]\n",
      "   [ 47.         42.1875     44.28125  ]\n",
      "   [ 45.0625     41.03125    43.03125  ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 46.03125    49.96875    40.96875  ]\n",
      "   [ 47.16211    50.15625    41.34961  ]\n",
      "   [ 44.94336    49.152344   41.496094 ]\n",
      "   ...\n",
      "   [ 52.177734   63.48047    49.117188 ]\n",
      "   [ 50.210938   61.185547   47.816406 ]\n",
      "   [ 45.32422    56.351562   45.197266 ]]\n",
      "\n",
      "  [[ 45.16211    49.09961    40.38672  ]\n",
      "   [ 46.509766   49.322266   41.03711  ]\n",
      "   [ 47.027344   49.90625    43.376953 ]\n",
      "   ...\n",
      "   [ 61.228516   72.16406    57.507812 ]\n",
      "   [ 56.47461    66.64453    53.10547  ]\n",
      "   [ 45.851562   57.726562   45.734375 ]]\n",
      "\n",
      "  [[ 46.554688   50.345703   44.740234 ]\n",
      "   [ 47.597656   50.46875    46.035156 ]\n",
      "   [ 46.316406   48.89258    44.10742  ]\n",
      "   ...\n",
      "   [ 60.314453   69.9043     47.859375 ]\n",
      "   [ 55.32617    64.828125   47.304688 ]\n",
      "   [ 49.126953   60.533203   49.33789  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 42.291016   43.26953    42.17578  ]\n",
      "   [ 38.253906   41.658203   41.501953 ]\n",
      "   [ 32.117188   36.91211    36.75586  ]\n",
      "   ...\n",
      "   [ 27.361328   28.361328   31.361328 ]\n",
      "   [ 26.314453   27.314453   30.1875   ]\n",
      "   [ 28.822266   30.759766   33.603516 ]]\n",
      "\n",
      "  [[ 36.54492    39.36914    37.58203  ]\n",
      "   [ 36.158203   39.36328    39.36328  ]\n",
      "   [ 36.191406   39.972656   39.972656 ]\n",
      "   ...\n",
      "   [ 27.029297   28.029297   31.935547 ]\n",
      "   [ 26.923828   27.923828   31.09375  ]\n",
      "   [ 27.169922   29.107422   31.257812 ]]\n",
      "\n",
      "  [[ 43.507812   46.56836    43.72461  ]\n",
      "   [ 40.23828    44.21289    43.42578  ]\n",
      "   [ 40.92383    44.61133    44.61133  ]\n",
      "   ...\n",
      "   [ 28.271484   29.271484   33.9375   ]\n",
      "   [ 27.96875    28.96875    32.33789  ]\n",
      "   [ 27.96875    29.90625    31.96875  ]]]\n",
      "\n",
      "\n",
      " [[[ 35.154785   35.15576    37.11035  ]\n",
      "   [ 37.123535   37.14209    38.15625  ]\n",
      "   [ 39.078125   38.27881    38.305176 ]\n",
      "   ...\n",
      "   [ 68.257324   67.3042     69.3042   ]\n",
      "   [ 67.237305   67.069824   69.09961  ]\n",
      "   [ 63.311523   65.03223    73.09277  ]]\n",
      "\n",
      "  [[ 40.68799    40.814453   41.75049  ]\n",
      "   [ 40.80957    43.05713    45.780273 ]\n",
      "   [ 42.851562   46.305664   47.055664 ]\n",
      "   ...\n",
      "   [166.5083    164.40625   165.86572  ]\n",
      "   [163.7793    159.41748   161.54004  ]\n",
      "   [166.85547   160.04883   171.95654  ]]\n",
      "\n",
      "  [[ 69.180176   70.06592    69.92285  ]\n",
      "   [ 79.04883    82.745605   83.38623  ]\n",
      "   [ 90.13135    97.06201    96.59326  ]\n",
      "   ...\n",
      "   [137.17285   133.40234   128.72363  ]\n",
      "   [141.11914   130.71533   123.27588  ]\n",
      "   [197.69873   179.38184   180.83252  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 16.015625   20.153809   25.461426 ]\n",
      "   [ 17.046875   19.992676   24.992676 ]\n",
      "   [ 17.934082   19.765625   24.831543 ]\n",
      "   ...\n",
      "   [ 31.44336    39.999023   42.541016 ]\n",
      "   [ 43.415527   44.969727   45.435547 ]\n",
      "   [ 64.36426    58.538574   42.02539  ]]\n",
      "\n",
      "  [[ 32.342285   35.43457    38.60791  ]\n",
      "   [ 33.458496   36.496582   38.820312 ]\n",
      "   [ 17.992676   21.805176   25.0708   ]\n",
      "   ...\n",
      "   [ 33.493164   46.203613   49.12451  ]\n",
      "   [ 44.42871    51.245605   54.0625   ]\n",
      "   [ 56.657227   57.18994    46.836426 ]]\n",
      "\n",
      "  [[ 16.654297   24.498047   25.529785 ]\n",
      "   [ 22.138672   29.983887   29.124512 ]\n",
      "   [ 16.28955    24.16455    24.41211  ]\n",
      "   ...\n",
      "   [ 39.78711    53.833984   57.72705  ]\n",
      "   [ 46.65039    54.90039    59.79248  ]\n",
      "   [ 52.043945   55.06006    50.061523 ]]]\n",
      "\n",
      "\n",
      " [[[ 29.95337    28.95337    32.95337  ]\n",
      "   [ 28.907715   27.953857   31.953857 ]\n",
      "   [ 28.858154   27.890625   32.59375  ]\n",
      "   ...\n",
      "   [ 33.078125   30.1875     34.264404 ]\n",
      "   [ 33.78125    30.890625   34.890625 ]\n",
      "   [ 33.96924    30.219238   34.313232 ]]\n",
      "\n",
      "  [[ 30.154785   28.872803   32.872803 ]\n",
      "   [ 28.017822   27.439697   31.439697 ]\n",
      "   [ 27.144287   26.671875   31.144287 ]\n",
      "   ...\n",
      "   [ 30.507324   28.738037   33.441162 ]\n",
      "   [ 31.671875   29.671875   33.671875 ]\n",
      "   [ 32.544678   29.967285   34.82666  ]]\n",
      "\n",
      "  [[ 27.43628    26.046875   30.046875 ]\n",
      "   [ 26.871338   26.293213   30.293213 ]\n",
      "   [ 25.837646   25.453125   29.453125 ]\n",
      "   ...\n",
      "   [ 28.728271   27.431396   32.296875 ]\n",
      "   [ 30.136963   28.136963   32.683838 ]\n",
      "   [ 29.516846   27.516846   32.453125 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 14.140625   16.06372    21.6875   ]\n",
      "   [ 14.808838   16.261963   22.546875 ]\n",
      "   [ 14.1623535  15.296875   22.162354 ]\n",
      "   ...\n",
      "   [ 14.730957   14.8654785  21.25     ]\n",
      "   [ 13.777588   14.230713   20.230713 ]\n",
      "   [ 13.076904   14.         20.       ]]\n",
      "\n",
      "  [[ 14.623535   16.623535   21.529053 ]\n",
      "   [ 14.189697   16.189697   21.223145 ]\n",
      "   [ 14.         15.296875   22.472412 ]\n",
      "   ...\n",
      "   [ 14.133301   14.430176   20.430176 ]\n",
      "   [ 13.283447   14.283447   20.671875 ]\n",
      "   [ 13.         14.         20.094482 ]]\n",
      "\n",
      "  [[ 14.093994   16.093994   21.969238 ]\n",
      "   [ 14.         16.         22.249268 ]\n",
      "   [ 14.         15.923096   23.59375  ]\n",
      "   ...\n",
      "   [ 12.483154   13.40625    19.40625  ]\n",
      "   [ 13.561035   14.561035   20.624268 ]\n",
      "   [ 13.125244   14.125244   20.140625 ]]]], shape=(32, 32, 32, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]], shape=(32, 43), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = keras.Sequential(\n",
    "    [\n",
    "        layers.Rescaling(1. / 255)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels are already one-hot encoded, now we have to normalize the images, that will be done in side the model (1st Sequential layer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(0.3),\n",
    "        layers.RandomZoom(0.2),\n",
    "        layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "    # Resize and rescale all datasets.\n",
    "    ds = ds.map(lambda x, y: (normalization_layer(x), y),\n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "\n",
    "    # Use data augmentation only on the training set.\n",
    "    if augment:\n",
    "        ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y),\n",
    "                    num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    # Use buffered prefetching on all datasets.\n",
    "    return ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "train_aug_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "val_ds = prepare(val_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare CNN Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                     restore_best_weights=True)\n",
    "                                                     \n",
    "SAVED_MODEL_PATH = 'model/ge_traffic_sign_recognition.h5'\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(SAVED_MODEL_PATH, \n",
    "                                                      monitor=\"val_loss\", \n",
    "                                                      mode=\"min\",\n",
    "                                                      save_best_only=True, \n",
    "                                                      verbose=1)\n",
    "\n",
    "\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiniVGGNet.build(width=IMG_WIDTH, height=IMG_HEIGHT, depth= 3, classes=len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2097664   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 43)                22059     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,188,107\n",
      "Trainable params: 2,186,699\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "lr = 1e-2\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr , weight_decay=lr /EPOCHS, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_aug_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 21:48:06.480354: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_2/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-02-18 21:48:07.278252: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\n",
      "2023-02-18 21:48:07.278452: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Possibly insufficient driver version: 525.89.2\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_2/conv2d/Relu' defined at (most recent call last):\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_16088/2350155715.py\", line 1, in <module>\n      history = model.fit(train_ds,\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/backend.py\", line 5369, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential_2/conv2d/Relu'\nDNN library is not found.\n\t [[{{node sequential_2/conv2d/Relu}}]] [Op:__inference_train_function_5977]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_ds,\n\u001b[1;32m      2\u001b[0m                         validation_data\u001b[39m=\u001b[39;49mval_ds,\n\u001b[1;32m      3\u001b[0m                         batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE,\n\u001b[1;32m      4\u001b[0m                         epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[1;32m      5\u001b[0m                         callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[0;32m~/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_2/conv2d/Relu' defined at (most recent call last):\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_16088/2350155715.py\", line 1, in <module>\n      history = model.fit(train_ds,\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/backend.py\", line 5369, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential_2/conv2d/Relu'\nDNN library is not found.\n\t [[{{node sequential_2/conv2d/Relu}}]] [Op:__inference_train_function_5977]"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "                        validation_data=val_ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy per Epoch\")\n",
    "\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(val_ds)\n",
    "loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(val_ds)\n",
    "for pred in predicted[:3]:\n",
    "    print(np.argmax(pred, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual_predicted_labels(dataset): \n",
    "  \"\"\"\n",
    "    Create a list of actual ground truth values and the predictions from the model.\n",
    "\n",
    "    Args:\n",
    "      dataset: An iterable data structure, such as a TensorFlow Dataset, with features and labels.\n",
    "\n",
    "    Return:\n",
    "      Ground truth and predicted values for a particular dataset.\n",
    "  \"\"\"\n",
    "  actual = [labels for _, labels in dataset.unbatch()]\n",
    "  predicted = model.predict(dataset)\n",
    "\n",
    "  actual = tf.stack(actual, axis=0)\n",
    "  actual =np.argmax(actual, axis=1) # because one hot encoded \n",
    "  predicted = tf.concat(predicted, axis=0)\n",
    "  predicted = tf.argmax(predicted, axis=1)\n",
    "\n",
    "  return actual, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual, predicted = get_actual_predicted_labels(val_ds)\n",
    "actual[:10], predicted[:10].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(actual, predicted,\n",
    "                            target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "German_Traffic_Sign_Recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d537c92fe30561e09db272b7a25ae30e6e2bc97a97b3734491f304a50020ffea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
