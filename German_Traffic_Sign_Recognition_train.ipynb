{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German_Traffic_Sign_Recognition\n",
    "## About Dataset\n",
    "### Context\n",
    "The [German Traffic Sign Benchmark](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign?datasetId=82373)\n",
    " is a multi-class, single-image classification challenge held at the International Joint Conference on Neural Networks (IJCNN) 2011. We cordially invite researchers from relevant fields to participate: The competition is designed to allow for participation without special domain knowledge. Our benchmark has the following properties:\n",
    "\n",
    "* Single-image, multi-class classification problem\n",
    "* More than 40 classes\n",
    "* More than 50,000 images in total\n",
    "* Large, lifelike database\n",
    "\n",
    "**Acknowledgements** \\\n",
    "INI Benchmark Website\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# ignore all the warning and debug information from tensorflow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from libs.nn.conv.lenet import LeNet\n",
    "from libs.nn.conv.minivggnet import MiniVGGNet\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus: \n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look into the data directory\n",
    "images_dir = './gtsrb-german-traffic-sign'\n",
    "\n",
    "dataset_dir = f'{images_dir}/Train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_WIDTH = IMG_HEIGHT = 64\n",
    "RANDOM_STATE=123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0: 'Speed limit (20km/h)',\n",
    "           1: 'Speed limit (30km/h)',\n",
    "           2: 'Speed limit (50km/h)',\n",
    "           3: 'Speed limit (60km/h)',\n",
    "           4: 'Speed limit (70km/h)',\n",
    "           5: 'Speed limit (80km/h)',\n",
    "           6: 'End of speed limit (80km/h)',\n",
    "           7: 'Speed limit (100km/h)',\n",
    "           8: 'Speed limit (120km/h)',\n",
    "           9: 'No passing',\n",
    "           10: 'No passing veh over 3.5 tons',\n",
    "           11: 'Right-of-way at intersection',\n",
    "           12: 'Priority road',\n",
    "           13: 'Yield',\n",
    "           14: 'Stop',\n",
    "           15: 'No vehicles',\n",
    "           16: 'Veh > 3.5 tons prohibited',\n",
    "           17: 'No entry',\n",
    "           18: 'General caution',\n",
    "           19: 'Dangerous curve left',\n",
    "           20: 'Dangerous curve right',\n",
    "           21: 'Double curve',\n",
    "           22: 'Bumpy road',\n",
    "           23: 'Slippery road',\n",
    "           24: 'Road narrows on the right',\n",
    "           25: 'Road work',\n",
    "           26: 'Traffic signals',\n",
    "           27: 'Pedestrians',\n",
    "           28: 'Children crossing',\n",
    "           29: 'Bicycles crossing',\n",
    "           30: 'Beware of ice/snow',\n",
    "           31: 'Wild animals crossing',\n",
    "           32: 'End speed + passing limits',\n",
    "           33: 'Turn right ahead',\n",
    "           34: 'Turn left ahead',\n",
    "           35: 'Ahead only',\n",
    "           36: 'Go straight or right',\n",
    "           37: 'Go straight or left',\n",
    "           38: 'Keep right',\n",
    "           39: 'Keep left',\n",
    "           40: 'Roundabout mandatory',\n",
    "           41: 'End of no passing',\n",
    "           42: 'End no passing veh > 3.5 tons'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39209 files belonging to 43 classes.\n",
      "Using 31368 files for training.\n",
      "Using 7841 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
    "  dataset_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"both\",\n",
    "  seed=RANDOM_STATE,\n",
    "  shuffle=True,\n",
    "  label_mode='categorical' ,\n",
    "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '2',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '3',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '4',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes  = train_ds.class_names\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 95.         96.         96.       ]\n",
      "   [ 95.36719    95.265625   94.16406  ]\n",
      "   [ 95.94531    94.109375   91.27344  ]\n",
      "   ...\n",
      "   [ 71.94531    75.94531    64.890625 ]\n",
      "   [ 71.36719    75.36719    63.734375 ]\n",
      "   [ 71.         75.         63.       ]]\n",
      "\n",
      "  [[ 96.5625     97.5625     98.734375 ]\n",
      "   [ 96.06909    96.254395   96.32471  ]\n",
      "   [ 95.29224    94.194824   92.53076  ]\n",
      "   ...\n",
      "   [ 71.59741    75.57605    64.91199  ]\n",
      "   [ 71.47095    75.223755   63.981567 ]\n",
      "   [ 71.390625   75.         63.390625 ]]\n",
      "\n",
      "  [[ 98.9375     99.9375    102.890625 ]\n",
      "   [ 97.13599    97.757324   99.60889  ]\n",
      "   [ 94.29956    94.32471    94.441895 ]\n",
      "   ...\n",
      "   [ 71.0686     75.01477    64.94446  ]\n",
      "   [ 71.62866    75.00574    64.3573   ]\n",
      "   [ 71.984375   75.         63.984375 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 97.90625   103.921875   83.90625  ]\n",
      "   [ 95.726074  102.4646     82.448975 ]\n",
      "   [ 92.29346   100.170166   80.15454  ]\n",
      "   ...\n",
      "   [ 55.976562   57.138916   50.19104  ]\n",
      "   [ 55.398438   58.2771     51.88025  ]\n",
      "   [ 55.03125    59.         52.953125 ]]\n",
      "\n",
      "  [[ 94.34375   100.953125   80.34375  ]\n",
      "   [ 93.035645   99.931885   79.32251  ]\n",
      "   [ 90.976074   98.323975   77.7146   ]\n",
      "   ...\n",
      "   [ 57.164062   58.261475   51.216187 ]\n",
      "   [ 56.585938   58.713135   51.189087 ]\n",
      "   [ 56.21875    59.         51.171875 ]]\n",
      "\n",
      "  [[ 92.         99.         78.       ]\n",
      "   [ 91.265625   98.265625   77.265625 ]\n",
      "   [ 90.109375   97.109375   76.109375 ]\n",
      "   ...\n",
      "   [ 57.945312   59.         51.890625 ]\n",
      "   [ 57.367188   59.         50.734375 ]\n",
      "   [ 57.         59.         50.       ]]]\n",
      "\n",
      "\n",
      " [[[ 51.         45.         41.       ]\n",
      "   [ 48.421875   42.421875   37.5625   ]\n",
      "   [ 48.         42.         36.234375 ]\n",
      "   ...\n",
      "   [ 84.640625   73.46875    60.46875  ]\n",
      "   [ 91.125      76.546875   63.546875 ]\n",
      "   [ 98.         86.         73.       ]]\n",
      "\n",
      "  [[ 52.53125    46.53125    42.53125  ]\n",
      "   [ 50.611084   44.611084   39.75171  ]\n",
      "   [ 48.53833    43.12451    37.358887 ]\n",
      "   ...\n",
      "   [ 87.11694    76.4834     62.897217 ]\n",
      "   [ 93.218506   80.721924   67.82959  ]\n",
      "   [ 94.171875   82.9375     70.703125 ]]\n",
      "\n",
      "  [[ 53.         46.390625   41.171875 ]\n",
      "   [ 53.375977   47.290283   41.21216  ]\n",
      "   [ 50.20752    44.973145   37.98877  ]\n",
      "   ...\n",
      "   [ 88.56055    78.52026    64.288086 ]\n",
      "   [ 90.8125     80.60986    67.83618  ]\n",
      "   [ 89.953125   79.5625     68.171875 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 59.171875   59.5625     49.171875 ]\n",
      "   [ 59.359863   58.891113   49.883545 ]\n",
      "   [ 66.31714    64.64307    54.163086 ]\n",
      "   ...\n",
      "   [ 51.517822   48.830322   43.986572 ]\n",
      "   [ 47.02368    46.633057   40.74243  ]\n",
      "   [ 44.78125    44.390625   36.78125  ]]\n",
      "\n",
      "  [[ 58.1875     59.1875     47.71875  ]\n",
      "   [ 58.53662    58.878662   48.269287 ]\n",
      "   [ 63.008057   62.07007    51.19458  ]\n",
      "   ...\n",
      "   [ 52.46924    49.40674    45.172363 ]\n",
      "   [ 47.82129    47.055664   41.807373 ]\n",
      "   [ 45.296875   44.53125    37.765625 ]]\n",
      "\n",
      "  [[ 49.         50.         37.       ]\n",
      "   [ 53.296875   54.296875   42.15625  ]\n",
      "   [ 57.828125   58.828125   47.59375  ]\n",
      "   ...\n",
      "   [ 52.0625     49.765625   45.53125  ]\n",
      "   [ 48.15625    48.15625    43.015625 ]\n",
      "   [ 43.         43.         37.       ]]]\n",
      "\n",
      "\n",
      " [[[ 36.         35.         37.       ]\n",
      "   [ 36.59375    35.296875   37.296875 ]\n",
      "   [ 37.65625    35.828125   37.828125 ]\n",
      "   ...\n",
      "   [ 46.515625   44.515625   46.34375  ]\n",
      "   [ 48.109375   46.109375   47.40625  ]\n",
      "   [ 49.         47.         48.       ]]\n",
      "\n",
      "  [[ 35.320312   34.320312   36.09375  ]\n",
      "   [ 35.981323   34.75171    36.592407 ]\n",
      "   [ 37.164185   35.52368    37.48474  ]\n",
      "   ...\n",
      "   [ 46.02356    44.02356    46.000366 ]\n",
      "   [ 47.49695    45.49695    46.701782 ]\n",
      "   [ 48.320312   46.320312   47.09375  ]]\n",
      "\n",
      "  [[ 33.867188   32.867188   34.15625  ]\n",
      "   [ 34.671997   33.58618    35.086304 ]\n",
      "   [ 36.112183   34.872803   36.75061  ]\n",
      "   ...\n",
      "   [ 44.971558   42.971558   45.266235 ]\n",
      "   [ 46.187622   44.187622   45.19568  ]\n",
      "   [ 46.867188   44.867188   45.15625  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 35.578125   33.578125   39.289062 ]\n",
      "   [ 35.66394    33.367065   39.374878 ]\n",
      "   [ 35.817505   32.98938    39.528442 ]\n",
      "   ...\n",
      "   [ 45.82312    41.705933   43.705933 ]\n",
      "   [ 44.382935   40.796997   42.796997 ]\n",
      "   [ 43.578125   40.289062   42.289062 ]]\n",
      "\n",
      "  [[ 36.546875   34.546875   39.773438 ]\n",
      "   [ 36.77649    34.479614   40.00305  ]\n",
      "   [ 37.187378   34.359253   40.41394  ]\n",
      "   ...\n",
      "   [ 46.390747   41.789185   43.789185 ]\n",
      "   [ 45.207886   41.137573   43.137573 ]\n",
      "   [ 44.546875   40.773438   42.773438 ]]\n",
      "\n",
      "  [[ 37.         35.         40.       ]\n",
      "   [ 37.296875   35.         40.296875 ]\n",
      "   [ 37.828125   35.         40.828125 ]\n",
      "   ...\n",
      "   [ 46.65625    41.828125   43.828125 ]\n",
      "   [ 45.59375    41.296875   43.296875 ]\n",
      "   [ 45.         41.         43.       ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 46.         50.         41.       ]\n",
      "   [ 46.34375    50.         41.       ]\n",
      "   [ 46.90625    50.         41.       ]\n",
      "   ...\n",
      "   [ 49.53125    60.53125    47.71875  ]\n",
      "   [ 46.71875    57.71875    46.03125  ]\n",
      "   [ 45.         56.         45.       ]]\n",
      "\n",
      "  [[ 45.703125   49.703125   40.703125 ]\n",
      "   [ 46.046875   49.703125   40.703125 ]\n",
      "   [ 46.609375   49.703125   40.703125 ]\n",
      "   ...\n",
      "   [ 51.145508   61.904297   49.063965 ]\n",
      "   [ 47.331055   58.42383    46.541504 ]\n",
      "   [ 45.         56.296875   45.       ]]\n",
      "\n",
      "  [[ 45.171875   49.171875   40.171875 ]\n",
      "   [ 45.515625   49.171875   40.171875 ]\n",
      "   [ 46.078125   49.171875   40.171875 ]\n",
      "   ...\n",
      "   [ 54.03418    64.36133    51.47119  ]\n",
      "   [ 48.426758   59.685547   47.45459  ]\n",
      "   [ 45.         56.828125   45.       ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 37.375      40.375      38.203125 ]\n",
      "   [ 37.13867    40.197754   38.71338  ]\n",
      "   [ 36.751953   39.907715   39.54834  ]\n",
      "   ...\n",
      "   [ 27.171875   28.265625   31.171875 ]\n",
      "   [ 27.171875   28.828125   31.171875 ]\n",
      "   [ 27.171875   29.171875   31.171875 ]]\n",
      "\n",
      "  [[ 41.625      44.625      41.921875 ]\n",
      "   [ 40.658203   43.899902   41.884277 ]\n",
      "   [ 39.07617    42.71338    41.822754 ]\n",
      "   ...\n",
      "   [ 27.703125   28.796875   31.703125 ]\n",
      "   [ 27.703125   29.359375   31.703125 ]\n",
      "   [ 27.703125   29.703125   31.703125 ]]\n",
      "\n",
      "  [[ 44.         47.         44.       ]\n",
      "   [ 42.625      45.96875    43.65625  ]\n",
      "   [ 40.375      44.28125    43.09375  ]\n",
      "   ...\n",
      "   [ 28.         29.09375    32.       ]\n",
      "   [ 28.         29.65625    32.       ]\n",
      "   [ 28.         30.         32.       ]]]\n",
      "\n",
      "\n",
      " [[[ 35.         35.         37.       ]\n",
      "   [ 35.546875   35.546875   37.273438 ]\n",
      "   [ 36.578125   36.578125   37.789062 ]\n",
      "   ...\n",
      "   [ 63.15625    63.578125   66.84375  ]\n",
      "   [ 61.09375    62.546875   68.90625  ]\n",
      "   [ 60.         62.         70.       ]]\n",
      "\n",
      "  [[ 36.1875     36.1875     37.890625 ]\n",
      "   [ 36.490845   36.6532     38.326416 ]\n",
      "   [ 37.062866   37.531372   39.148193 ]\n",
      "   ...\n",
      "   [ 93.562744   92.54663    96.35962  ]\n",
      "   [ 91.8064     91.20923    98.72827  ]\n",
      "   [ 90.875      90.5        99.984375 ]]\n",
      "\n",
      "  [[ 38.3125     38.3125     39.484375 ]\n",
      "   [ 38.180054   38.632935   40.210693 ]\n",
      "   [ 37.930298   39.237183   41.580322 ]\n",
      "   ...\n",
      "   [147.97437   144.38501   149.17749  ]\n",
      "   [146.76587   142.49976   152.094    ]\n",
      "   [146.125     141.5       153.64062  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 30.90625    34.765625   37.421875 ]\n",
      "   [ 31.641113   35.50049    37.836304 ]\n",
      "   [ 33.026855   36.88623    38.617798 ]\n",
      "   ...\n",
      "   [ 47.446533   53.389038   54.099365 ]\n",
      "   [ 52.58667    55.524048   49.79712  ]\n",
      "   [ 55.3125     56.65625    47.515625 ]]\n",
      "\n",
      "  [[ 21.34375    27.859375   29.453125 ]\n",
      "   [ 22.659668   29.175293   30.303345 ]\n",
      "   [ 25.141113   31.656738   31.906616 ]\n",
      "   ...\n",
      "   [ 47.83667    54.422485   56.531494 ]\n",
      "   [ 51.333252   55.187866   51.681396 ]\n",
      "   [ 53.1875     55.59375    49.109375 ]]\n",
      "\n",
      "  [[ 16.         24.         25.       ]\n",
      "   [ 17.640625   25.640625   26.09375  ]\n",
      "   [ 20.734375   28.734375   28.15625  ]\n",
      "   ...\n",
      "   [ 48.054688   55.         57.890625 ]\n",
      "   [ 50.632812   55.         52.734375 ]\n",
      "   [ 52.         55.         50.       ]]]\n",
      "\n",
      "\n",
      " [[[ 30.         29.         33.       ]\n",
      "   [ 29.539062   28.539062   32.539062 ]\n",
      "   [ 29.         28.         32.       ]\n",
      "   ...\n",
      "   [ 34.         31.         35.       ]\n",
      "   [ 34.         30.460938   34.460938 ]\n",
      "   [ 34.         30.         34.       ]]\n",
      "\n",
      "  [[ 30.414062   29.414062   33.414062 ]\n",
      "   [ 29.762268   28.762268   32.762268 ]\n",
      "   [ 28.915894   27.957947   31.957947 ]\n",
      "   ...\n",
      "   [ 33.171875   30.585938   34.585938 ]\n",
      "   [ 33.618286   30.493286   34.71649  ]\n",
      "   [ 34.         30.414062   34.828125 ]]\n",
      "\n",
      "  [[ 30.953125   29.929688   33.929688 ]\n",
      "   [ 30.052856   29.040222   33.040222 ]\n",
      "   [ 28.794495   27.896057   31.896057 ]\n",
      "   ...\n",
      "   [ 31.976562   29.976562   33.976562 ]\n",
      "   [ 33.016785   30.490356   35.02942  ]\n",
      "   [ 33.90625    30.929688   35.929688 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 14.9765625  16.976562   21.976562 ]\n",
      "   [ 14.537231   16.537231   21.087097 ]\n",
      "   [ 14.021057   16.021057   20.24524  ]\n",
      "   ...\n",
      "   [ 13.099182   14.099182   20.976562 ]\n",
      "   [ 13.         14.         20.450134 ]\n",
      "   [ 13.         14.         20.       ]]\n",
      "\n",
      "  [[ 14.4140625  16.414062   22.       ]\n",
      "   [ 14.223206   16.223206   21.618286 ]\n",
      "   [ 14.         16.         21.31549  ]\n",
      "   ...\n",
      "   [ 13.568481   14.568481   20.94049  ]\n",
      "   [ 13.270081   14.270081   20.460938 ]\n",
      "   [ 13.         14.         20.       ]]\n",
      "\n",
      "  [[ 14.         16.         22.       ]\n",
      "   [ 14.         16.         22.       ]\n",
      "   [ 14.         16.         22.101562 ]\n",
      "   ...\n",
      "   [ 13.8984375  14.8984375  20.898438 ]\n",
      "   [ 13.4609375  14.4609375  20.460938 ]\n",
      "   [ 13.         14.         20.       ]]]], shape=(32, 64, 64, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]], shape=(32, 43), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = keras.Sequential(\n",
    "    [\n",
    "        layers.Rescaling(1. / 255)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels are already one-hot encoded, now we have to normalize the images, that will be done in side the model (1st Sequential layer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(0.3),\n",
    "        layers.RandomZoom(0.2),\n",
    "        layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "    # Resize and rescale all datasets.\n",
    "    ds = ds.map(lambda x, y: (normalization_layer(x), y),\n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "\n",
    "    # Use data augmentation only on the training set.\n",
    "    if augment:\n",
    "        ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y),\n",
    "                    num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    # Use buffered prefetching on all datasets.\n",
    "    return ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/viv/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "train_aug_ds = prepare(train_ds, shuffle=False, augment=False)\n",
    "val_ds = prepare(val_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare CNN Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping_cb = keras.callbacks.EarlyStopping(patience=20,\n",
    "#                                                      restore_best_weights=True)\n",
    "                                                     \n",
    "# SAVED_MODEL_PATH = 'model/ge_traffic_sign_recognition.h5'\n",
    "# model_checkpoint_cb = keras.callbacks.ModelCheckpoint(SAVED_MODEL_PATH, \n",
    "#                                                       monitor=\"val_loss\", \n",
    "#                                                       mode=\"min\",\n",
    "#                                                       save_best_only=True, \n",
    "#                                                       verbose=1)\n",
    "\n",
    "# run_index = 1 # increment every time you train the model\n",
    "# run_logdir = Path() / \"ge_traffic_sign_recog\" / f\"run_{run_index:03d}\"\n",
    "# tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "# callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiniVGGNet.build(width=IMG_WIDTH, height=IMG_HEIGHT, depth= 3, classes=len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64, 64, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64, 64, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 32, 32, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               8389120   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 43)                22059     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,479,563\n",
      "Trainable params: 8,478,155\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "lr = 1e-2\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr , weight_decay=lr /EPOCHS, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 20:58:34.575106: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_2/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981/981 [==============================] - 10s 8ms/step - loss: 0.8506 - accuracy: 0.7738 - val_loss: 5.5023 - val_accuracy: 0.0533\n",
      "Epoch 2/100\n",
      "981/981 [==============================] - 8s 8ms/step - loss: 0.1105 - accuracy: 0.9672 - val_loss: 18.2835 - val_accuracy: 0.0172\n",
      "Epoch 3/100\n",
      "981/981 [==============================] - 8s 8ms/step - loss: 0.0619 - accuracy: 0.9821 - val_loss: 45.9093 - val_accuracy: 0.0170\n",
      "Epoch 4/100\n",
      "981/981 [==============================] - 8s 8ms/step - loss: 0.0351 - accuracy: 0.9891 - val_loss: 39.3728 - val_accuracy: 0.0292\n",
      "Epoch 5/100\n",
      "981/981 [==============================] - 8s 8ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 71.9695 - val_accuracy: 0.0564\n",
      "Epoch 6/100\n",
      "981/981 [==============================] - 8s 8ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 20.4278 - val_accuracy: 0.0551\n",
      "Epoch 7/100\n",
      "981/981 [==============================] - 8s 8ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 35.9991 - val_accuracy: 0.0101\n",
      "Epoch 8/100\n",
      "981/981 [==============================] - 8s 8ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 54.3909 - val_accuracy: 0.0069\n",
      "Epoch 9/100\n",
      "981/981 [==============================] - 7s 8ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 58.7451 - val_accuracy: 0.0087\n",
      "Epoch 10/100\n",
      "981/981 [==============================] - 8s 8ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 72.2624 - val_accuracy: 0.0087\n",
      "Epoch 11/100\n",
      "981/981 [==============================] - 8s 8ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 76.8895 - val_accuracy: 0.0069\n",
      "Epoch 12/100\n",
      "718/981 [====================>.........] - ETA: 1s - loss: 0.0026 - accuracy: 0.9996"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_ds,\n\u001b[1;32m      2\u001b[0m                         validation_data\u001b[39m=\u001b[39;49mval_ds,\n\u001b[1;32m      3\u001b[0m                         batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE,\n\u001b[1;32m      4\u001b[0m                         epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[1;32m      5\u001b[0m                         callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[0;32m~/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/German_Traffic_Sign_Recognition/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "                        validation_data=val_ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy per Epoch\")\n",
    "\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(val_ds)\n",
    "loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(val_ds)\n",
    "for pred in predicted[:3]:\n",
    "    print(np.argmax(pred, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual_predicted_labels(dataset): \n",
    "  \"\"\"\n",
    "    Create a list of actual ground truth values and the predictions from the model.\n",
    "\n",
    "    Args:\n",
    "      dataset: An iterable data structure, such as a TensorFlow Dataset, with features and labels.\n",
    "\n",
    "    Return:\n",
    "      Ground truth and predicted values for a particular dataset.\n",
    "  \"\"\"\n",
    "  actual = [labels for _, labels in dataset.unbatch()]\n",
    "  predicted = model.predict(dataset)\n",
    "\n",
    "  actual = tf.stack(actual, axis=0)\n",
    "  actual =np.argmax(actual, axis=1) # because one hot encoded \n",
    "  predicted = tf.concat(predicted, axis=0)\n",
    "  predicted = tf.argmax(predicted, axis=1)\n",
    "\n",
    "  return actual, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual, predicted = get_actual_predicted_labels(val_ds)\n",
    "actual[:10], predicted[:10].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(actual, predicted,\n",
    "                            target_names=classes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "German_Traffic_Sign_Recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d537c92fe30561e09db272b7a25ae30e6e2bc97a97b3734491f304a50020ffea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
