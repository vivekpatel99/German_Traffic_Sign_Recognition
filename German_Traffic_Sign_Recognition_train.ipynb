{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German_Traffic_Sign_Recognition\n",
    "## About Dataset\n",
    "### Context\n",
    "The [German Traffic Sign Benchmark](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign?datasetId=82373)\n",
    " is a multi-class, single-image classification challenge held at the International Joint Conference on Neural Networks (IJCNN) 2011. We cordially invite researchers from relevant fields to participate: The competition is designed to allow for participation without special domain knowledge. Our benchmark has the following properties:\n",
    "\n",
    "* Single-image, multi-class classification problem\n",
    "* More than 40 classes\n",
    "* More than 50,000 images in total\n",
    "* Large, lifelike database\n",
    "\n",
    "**Acknowledgements** \\\n",
    "INI Benchmark Website\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# ignore all the warning and debug information from tensorflow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from libs.nn.conv import CNN\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from libs.preprocessing import ImageToArrayPreprocessor\n",
    "from libs.preprocessing import SimplePreprocessor\n",
    "from libs.datasets import SimpleDatasetLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from libs.utils.myplot import plot_confusion_matrix\n",
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look into the data directory\n",
    "images_dir = './gtsrb-german-traffic-sign'\n",
    "\n",
    "\n",
    "dataset_dir = f'{images_dir}/Train'\n",
    "dataset_imgs = list(paths.list_images(dataset_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_WIDTH = IMG_HEIGHT = 32\n",
    "RANDOM_STATE=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0: 'Speed limit (20km/h)',\n",
    "           1: 'Speed limit (30km/h)',\n",
    "           2: 'Speed limit (50km/h)',\n",
    "           3: 'Speed limit (60km/h)',\n",
    "           4: 'Speed limit (70km/h)',\n",
    "           5: 'Speed limit (80km/h)',\n",
    "           6: 'End of speed limit (80km/h)',\n",
    "           7: 'Speed limit (100km/h)',\n",
    "           8: 'Speed limit (120km/h)',\n",
    "           9: 'No passing',\n",
    "           10: 'No passing veh over 3.5 tons',\n",
    "           11: 'Right-of-way at intersection',\n",
    "           12: 'Priority road',\n",
    "           13: 'Yield',\n",
    "           14: 'Stop',\n",
    "           15: 'No vehicles',\n",
    "           16: 'Veh > 3.5 tons prohibited',\n",
    "           17: 'No entry',\n",
    "           18: 'General caution',\n",
    "           19: 'Dangerous curve left',\n",
    "           20: 'Dangerous curve right',\n",
    "           21: 'Double curve',\n",
    "           22: 'Bumpy road',\n",
    "           23: 'Slippery road',\n",
    "           24: 'Road narrows on the right',\n",
    "           25: 'Road work',\n",
    "           26: 'Traffic signals',\n",
    "           27: 'Pedestrians',\n",
    "           28: 'Children crossing',\n",
    "           29: 'Bicycles crossing',\n",
    "           30: 'Beware of ice/snow',\n",
    "           31: 'Wild animals crossing',\n",
    "           32: 'End speed + passing limits',\n",
    "           33: 'Turn right ahead',\n",
    "           34: 'Turn left ahead',\n",
    "           35: 'Ahead only',\n",
    "           36: 'Go straight or right',\n",
    "           37: 'Go straight or left',\n",
    "           38: 'Keep right',\n",
    "           39: 'Keep left',\n",
    "           40: 'Roundabout mandatory',\n",
    "           41: 'End of no passing',\n",
    "           42: 'End no passing veh > 3.5 tons'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 500/39209\n",
      "[INFO] processed 1000/39209\n",
      "[INFO] processed 1500/39209\n",
      "[INFO] processed 2000/39209\n",
      "[INFO] processed 2500/39209\n",
      "[INFO] processed 3000/39209\n",
      "[INFO] processed 3500/39209\n",
      "[INFO] processed 4000/39209\n",
      "[INFO] processed 4500/39209\n",
      "[INFO] processed 5000/39209\n",
      "[INFO] processed 5500/39209\n",
      "[INFO] processed 6000/39209\n",
      "[INFO] processed 6500/39209\n",
      "[INFO] processed 7000/39209\n",
      "[INFO] processed 7500/39209\n",
      "[INFO] processed 8000/39209\n",
      "[INFO] processed 8500/39209\n",
      "[INFO] processed 9000/39209\n",
      "[INFO] processed 9500/39209\n",
      "[INFO] processed 10000/39209\n",
      "[INFO] processed 10500/39209\n",
      "[INFO] processed 11000/39209\n",
      "[INFO] processed 11500/39209\n",
      "[INFO] processed 12000/39209\n",
      "[INFO] processed 12500/39209\n",
      "[INFO] processed 13000/39209\n",
      "[INFO] processed 13500/39209\n",
      "[INFO] processed 14000/39209\n",
      "[INFO] processed 14500/39209\n",
      "[INFO] processed 15000/39209\n",
      "[INFO] processed 15500/39209\n",
      "[INFO] processed 16000/39209\n",
      "[INFO] processed 16500/39209\n",
      "[INFO] processed 17000/39209\n",
      "[INFO] processed 17500/39209\n",
      "[INFO] processed 18000/39209\n",
      "[INFO] processed 18500/39209\n",
      "[INFO] processed 19000/39209\n",
      "[INFO] processed 19500/39209\n",
      "[INFO] processed 20000/39209\n",
      "[INFO] processed 20500/39209\n",
      "[INFO] processed 21000/39209\n",
      "[INFO] processed 21500/39209\n",
      "[INFO] processed 22000/39209\n",
      "[INFO] processed 22500/39209\n",
      "[INFO] processed 23000/39209\n",
      "[INFO] processed 23500/39209\n",
      "[INFO] processed 24000/39209\n",
      "[INFO] processed 24500/39209\n",
      "[INFO] processed 25000/39209\n",
      "[INFO] processed 25500/39209\n",
      "[INFO] processed 26000/39209\n",
      "[INFO] processed 26500/39209\n",
      "[INFO] processed 27000/39209\n",
      "[INFO] processed 27500/39209\n",
      "[INFO] processed 28000/39209\n",
      "[INFO] processed 28500/39209\n",
      "[INFO] processed 29000/39209\n",
      "[INFO] processed 29500/39209\n",
      "[INFO] processed 30000/39209\n",
      "[INFO] processed 30500/39209\n",
      "[INFO] processed 31000/39209\n",
      "[INFO] processed 31500/39209\n",
      "[INFO] processed 32000/39209\n",
      "[INFO] processed 32500/39209\n",
      "[INFO] processed 33000/39209\n",
      "[INFO] processed 33500/39209\n",
      "[INFO] processed 34000/39209\n",
      "[INFO] processed 34500/39209\n",
      "[INFO] processed 35000/39209\n",
      "[INFO] processed 35500/39209\n",
      "[INFO] processed 36000/39209\n",
      "[INFO] processed 36500/39209\n",
      "[INFO] processed 37000/39209\n",
      "[INFO] processed 37500/39209\n",
      "[INFO] processed 38000/39209\n",
      "[INFO] processed 38500/39209\n",
      "[INFO] processed 39000/39209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((39209, 32, 32, 3), (39209,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the image preprocessor\n",
    "sp = SimplePreprocessor(IMG_WIDTH, IMG_HEIGHT)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "\n",
    "# load the dataset from disk \n",
    "sdl = SimpleDatasetLoader(preprocessors=[sp, iap])\n",
    "\n",
    "X, y = sdl.load(dataset_imgs, verbose=500)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= X.astype(\"float\") / 255.0\n",
    "np.min(X), np.max(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into train, and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31367, 32, 32, 3), (7842, 32, 32, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate 20% validation dataset\n",
    "X_train, _X_valid, y_train, _y_valid = train_test_split(X, y, \n",
    "                                                    test_size=0.20, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y,\n",
    "                                                    random_state=RANDOM_STATE \n",
    "                                                    )\n",
    "\n",
    "X_train.shape, _X_valid.shape                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5489, 32, 32, 3), (2353, 32, 32, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate 30% dataset for testing from validation\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(_X_valid, _y_valid, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=RANDOM_STATE \n",
    "                                                    )\n",
    "X_valid.shape, X_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  6,  6, ..., 29, 29, 29])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CNN() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cnn_model \u001b[39m=\u001b[39m CNN(width\u001b[39m=\u001b[39;49mIMG_WIDTH, heigth\u001b[39m=\u001b[39;49mIMG_HEIGHT, depth\u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m, classes\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(np\u001b[39m.\u001b[39;49munique(y)))\n",
      "\u001b[0;31mTypeError\u001b[0m: CNN() takes no arguments"
     ]
    }
   ],
   "source": [
    "cnn_model = CNN(width=IMG_WIDTH, heigth=IMG_HEIGHT, depth= 3, classes=len(np.unique(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "German_Traffic_Sign_Recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d537c92fe30561e09db272b7a25ae30e6e2bc97a97b3734491f304a50020ffea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
